{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=nn.quantized.Embedding(10,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[8, 5, 7, 7, 9, 3, 3, 9, 3, 6]]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inx=torch.randint(low=1,high=10,size=(1,10))\n",
    "inx,inx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([8, 5, 7, 7, 9, 3, 3, 9, 3, 6]), torch.Size([10]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inx=inx.squeeze()\n",
    "inx,inx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 216.,  78.,  41., 150.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "         [ 91., 127.,   0.,   0., 104., 105., 100., 100., 101., 110.,  44.,  32.],\n",
       "         [ 92.,   2.,   0.,   0., 125.,   5., 125.,   6., 116.,   5.,   0.,   0.],\n",
       "         [ 92.,   2.,   0.,   0., 125.,   5., 125.,   6., 116.,   5.,   0.,   0.],\n",
       "         [ 91., 127.,   0.,   0., 104., 105., 100., 100., 101., 110.,  44.,  32.],\n",
       "         [ 92.,   2.,   0.,   0., 125.,   5., 125.,   6., 116.,   5.,   0.,   0.],\n",
       "         [101., 110.,  41.,  10.,  32.,  32.,  32.,  32.,   0.,   0.,   0.,   0.]]),\n",
       " torch.Size([10, 12]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=m(inx)\n",
    "output,output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40.4167,  0.0000,  0.0000,  0.0000, 76.1667, 39.6667, 39.6667, 76.1667,\n",
       "        39.6667, 32.5000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=torch.mean(output,dim=1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4892e-16, 4.1707e-34, 4.1707e-34, 4.1707e-34, 5.0000e-01, 7.0343e-17,\n",
      "        7.0343e-17, 5.0000e-01, 7.0343e-17, 5.4297e-20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adminroot/miniconda3/envs/distill_data/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use softmax convert elem in d to prob of (0,1)\n",
    "m=torch.nn.Softmax()(d)\n",
    "print(m)\n",
    "sum=0\n",
    "for i in m:\n",
    "    sum+=i\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50],\n",
       "        [50],\n",
       "        [50],\n",
       "        [50],\n",
       "        [50]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5,1,dtype=torch.long).fill_(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15,  8,  6, 14, 18,  8, 18,  5, 16,  6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=torch.randint(0,20,(10,),dtype=torch.long)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,ind=d.topk(2)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6],\n",
       "        [4]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.unsqueeze(-1).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[3, 2, 0, 7, 9]]),\n",
       "  tensor([[0, 8, 1, 6, 6]]),\n",
       "  tensor([[7, 3, 7, 1, 9]])],\n",
       " torch.Size([1, 5]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randint(0,10,(1,5))\n",
    "b=torch.randint(0,10,(1,5))\n",
    "c=torch.randint(0,10,(1,5))\n",
    "t=[a,b,c]\n",
    "t,a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2, 0, 7, 9, 0, 8, 1, 6, 6, 7, 3, 7, 1, 9]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(t,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9, 0, 9, 7, 3]],\n",
       "\n",
       "        [[2, 2, 6, 8, 4]],\n",
       "\n",
       "        [[1, 5, 9, 3, 6]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(t,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7704,  0.5047, -1.2166],\n",
       "        [ 0.3002, -1.7426,  1.3721]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7704,  0.5047, -1.2166,  0.3002, -1.7426,  1.3721])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4251, -1.5757,  0.7354,  1.5018,  1.0008,  0.8490,  0.8673, -1.0470,\n",
       "          1.3404,  0.3551]),\n",
       " tensor([-1.5025, -0.0942, -1.0042, -0.9562, -1.1521, -0.7583, -0.5511, -2.0398,\n",
       "          1.2891, -0.3689]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.randn((10))\n",
    "b=torch.randn((10))\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4012, -0.9179,  0.6264,  0.9055,  0.7619,  0.6905,  0.7000, -0.7806,\n",
       "         0.8718,  0.3409])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tanh(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9056, -0.0939, -0.7634, -0.7426, -0.8184, -0.6401, -0.5014, -0.9667,\n",
       "         0.8589, -0.3530])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tanh(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.40121553911144925"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "i=math.exp(a[0])\n",
    "j=math.exp(-a[0])\n",
    "(i-j)/(i+j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1849],\n",
       "          [-1.5822],\n",
       "          [-1.2110],\n",
       "          [-0.2608]],\n",
       " \n",
       "         [[-1.8215],\n",
       "          [ 0.6520],\n",
       "          [ 0.9071],\n",
       "          [ 0.5380]],\n",
       " \n",
       "         [[-1.6182],\n",
       "          [-0.8522],\n",
       "          [-0.2467],\n",
       "          [ 0.4484]]]),\n",
       " torch.Size([3, 4, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.randn((3,4,1))\n",
    "c,c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1849, -1.5822, -1.2110, -0.2608]],\n",
       "\n",
       "        [[-1.8215,  0.6520,  0.9071,  0.5380]],\n",
       "\n",
       "        [[-1.6182, -0.8522, -0.2467,  0.4484]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.squeeze(2).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1849, -1.5822, -1.2110, -0.2608]],\n",
       "\n",
       "        [[-1.8215,  0.6520,  0.9071,  0.5380]],\n",
       "\n",
       "        [[-1.6182, -0.8522, -0.2467,  0.4484]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5343, -0.7017,  1.1302, -4.0544, -4.7434]],\n",
       "\n",
       "        [[ 0.3598, -1.7984, -0.3229,  1.5098,  5.6372]],\n",
       "\n",
       "        [[ 0.1253,  0.8635, -0.4858, -0.2872, -0.6174]],\n",
       "\n",
       "        [[ 0.3907,  1.7180, -2.0073, -0.9748, -0.0188]],\n",
       "\n",
       "        [[-0.6374, -1.8763, -0.3272, -2.8946,  1.3741]],\n",
       "\n",
       "        [[ 3.4298,  4.5729,  3.6315,  2.2706, -4.1750]],\n",
       "\n",
       "        [[-0.7933,  1.4687,  0.4660,  0.1995,  0.6310]],\n",
       "\n",
       "        [[ 1.3289, -1.0014, -0.2890,  0.3842, -0.7253]],\n",
       "\n",
       "        [[ 3.6787, -2.1554,  0.0613,  0.7050, -0.8340]],\n",
       "\n",
       "        [[-1.9287, -0.7844, -1.4627,  1.2550, -1.5534]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.randn(10,1,4)\n",
    "mat2=torch.randn(10,4,5)\n",
    "torch.bmm(input,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnn=torch.nn.GRU(10,20,2,batch_first=True)\n",
    "input=torch.randn(3,5,10) # [batch_size,seq_len,hidden_size]\n",
    "h0=torch.randn(2,3,20) #[num_layer,batch_size,hidden_size]\n",
    "output,hn=rnn(input,h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0966,  0.0850, -0.0144, -0.2492,  0.0882, -0.0528, -0.0668,\n",
       "           0.1133,  0.0476, -0.1433,  0.0973,  0.1918, -0.3929, -0.3457,\n",
       "          -0.1468, -0.0566,  0.0626, -0.0078, -0.1233,  0.2845],\n",
       "         [ 0.2307,  0.0486,  0.2958,  0.1308,  0.1187, -0.0956,  0.0679,\n",
       "           0.0884, -0.0963,  0.0533,  0.0500,  0.1931,  0.0765, -0.0785,\n",
       "           0.0665, -0.0759, -0.1055,  0.3894, -0.0139,  0.0137],\n",
       "         [ 0.0509,  0.0526,  0.2739,  0.1720, -0.3999,  0.0031, -0.4146,\n",
       "           0.2687, -0.0571,  0.0435,  0.1527,  0.4541, -0.2086, -0.2708,\n",
       "           0.2138, -0.2714, -0.2830,  0.0140,  0.2017,  0.0535]],\n",
       "\n",
       "        [[-0.0986, -0.0183,  0.2382,  0.2471, -0.2534,  0.0755, -0.1397,\n",
       "          -0.0832,  0.0924, -0.1394, -0.0636, -0.2700,  0.1233, -0.0867,\n",
       "           0.0151, -0.3005, -0.0531, -0.1015,  0.0633, -0.0560],\n",
       "         [-0.3238, -0.0675,  0.2915,  0.3658, -0.4095, -0.0069, -0.2255,\n",
       "          -0.0271,  0.0368, -0.0059, -0.0390, -0.3401,  0.2954, -0.0949,\n",
       "          -0.0490, -0.3966, -0.0942, -0.0827,  0.2305, -0.1416],\n",
       "         [-0.3413,  0.0625,  0.1871,  0.5019, -0.5927,  0.1443, -0.1088,\n",
       "          -0.3461, -0.1001, -0.0429,  0.1944, -0.2705,  0.1551, -0.1525,\n",
       "          -0.1067, -0.4334, -0.1448, -0.0628,  0.0088, -0.1077]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size(),hn.size()\n",
    "hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4571,  0.5620, -0.6793,  1.5398],\n",
       "         [-2.3515, -0.1488,  0.2870, -0.3212],\n",
       "         [ 0.6668,  1.3626, -0.3457, -0.7709]],\n",
       "\n",
       "        [[ 0.0990, -1.0614,  0.2690, -0.9231],\n",
       "         [ 1.0972,  0.2956,  0.8115, -1.0920],\n",
       "         [-0.3299,  1.3630, -0.9358, -0.0810]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp=torch.randn(2,3,4)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4571,  0.5620, -0.6793,  1.5398],\n",
       "         [ 0.0990, -1.0614,  0.2690, -0.9231]],\n",
       "\n",
       "        [[-2.3515, -0.1488,  0.2870, -0.3212],\n",
       "         [ 1.0972,  0.2956,  0.8115, -1.0920]],\n",
       "\n",
       "        [[ 0.6668,  1.3626, -0.3457, -0.7709],\n",
       "         [-0.3299,  1.3630, -0.9358, -0.0810]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv=torch.randn(4,5,6)\n",
    "uv=torch.randn(4,5,6)\n",
    "L=torch.nn.Linear(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv=wv.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/adminroot/code/pc/study_vlog/deeplearning/torch_tutorial/tanslation_with_tf/demo.ipynb 单元格 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.16.75.84/home/adminroot/code/pc/study_vlog/deeplearning/torch_tutorial/tanslation_with_tf/demo.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m vv\u001b[39m=\u001b[39mL(wv)\u001b[39m+\u001b[39;49mL(uv)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "vv=L(wv)+L(uv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 6])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0897,  1.3601,  0.6858, -0.2313,  0.2795]],\n",
       "\n",
       "        [[-0.2727,  0.6991,  0.2556, -0.6225, -1.8562]],\n",
       "\n",
       "        [[ 0.0202,  0.8290,  0.3112, -1.7516, -0.4652]]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top=torch.randn(3,1,5)\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,topi=top.topk(1)\n",
    "topi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topi.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topi.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distill_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
